import torch
import numpy as np
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os
from network.teacher_student_plus import StudentEncoder, SimpleDecoder


# ---------------- Dataset ---------------- #
class FusionTestDataset(Dataset):
    def __init__(self, vi_dir, ir_dir, transform=None):
        self.vi_paths = sorted([os.path.join(vi_dir, f) for f in os.listdir(vi_dir) if f.endswith(('.png', '.jpg'))])
        self.ir_paths = sorted([os.path.join(ir_dir, f) for f in os.listdir(ir_dir) if f.endswith(('.png', '.jpg'))])
        self.transform = transform

    def __len__(self):
        return min(len(self.vi_paths), len(self.ir_paths))

    def __getitem__(self, idx):
        vi = Image.open(self.vi_paths[idx]).convert('RGB')
        ir = Image.open(self.ir_paths[idx]).convert('RGB')
        name = os.path.basename(self.vi_paths[idx])
        if self.transform:
            vi = self.transform(vi)
            ir = self.transform(ir)
        return vi, ir, name


# ---------------- Save Image ---------------- #
def save_reconstructed_image(tensor, path):
    """ä¿å­˜é‡æ„å›¾åƒï¼Œå¤„ç†å•é€šé“ç°åº¦å›¾"""
    array = tensor.squeeze().cpu().numpy()  # ç§»é™¤æ‰¹æ¬¡å’Œé€šé“ç»´åº¦
    array = np.clip(array * 255.0, 0, 255).astype(np.uint8)  # å½’ä¸€åŒ–åˆ°0-255
    Image.fromarray(array).save(path)


# ---------------- Inference ---------------- #
@torch.no_grad()
def run_reconstruction_test(student_ckpt, decoder_ckpt, vi_dir, ir_dir, output_dir):
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ŒåŒºåˆ†ä¸åŒç‰¹å¾ç»„åˆçš„é‡æ„ç»“æœ
    os.makedirs(output_dir, exist_ok=True)

    # åŸå§‹é‡æ„ç»“æœç›®å½•
    vi_recon_dir = os.path.join(output_dir, "vi_shared_vi_diff")
    ir_recon_dir = os.path.join(output_dir, "ir_shared_ir_diff")

    # æ–°å¢ç‰¹å¾ç»„åˆç›®å½•
    vi_shared_ir_diff_dir = os.path.join(output_dir, "vi_shared_ir_diff")
    ir_shared_vi_diff_dir = os.path.join(output_dir, "ir_shared_vi_diff")

    # åˆ›å»ºæ‰€æœ‰ç›®å½•
    for dir_path in [vi_recon_dir, ir_recon_dir, vi_shared_ir_diff_dir, ir_shared_vi_diff_dir]:
        os.makedirs(dir_path, exist_ok=True)

    # æ¨¡å‹åŠ è½½
    student = StudentEncoder().cuda()
    decoder = SimpleDecoder().cuda()

    # åŠ è½½æƒé‡
    student.load_state_dict(torch.load(student_ckpt))
    decoder.load_state_dict(torch.load(decoder_ckpt))

    student.eval()
    decoder.eval()

    # æ•°æ®é¢„å¤„ç†
    transform = transforms.ToTensor()
    dataset = FusionTestDataset(vi_dir, ir_dir, transform=transform)
    loader = DataLoader(dataset, batch_size=1, shuffle=False)

    print(f"ğŸš€ Starting reconstruction on {len(dataset)} pairs...")

    for batch_idx, (vi, ir, name) in enumerate(loader):
        vi, ir = vi.cuda(), ir.cuda()
        base_name = name[0].split('.')[0]  # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰

        # æå–ç‰¹å¾
        f_shared_vi, f_diff_vi = student(vi)
        f_shared_ir, f_diff_ir = student(ir)

        # ---------------- åŸå§‹é‡æ„æ–¹å¼ ---------------- #
        # å¯è§å…‰å›¾åƒé‡æ„ (vi_shared + vi_diff)
        vi_recon_input = torch.cat([f_shared_vi, f_diff_vi], dim=1)
        vi_recon = decoder(vi_recon_input)
        vi_recon = (vi_recon - torch.min(vi_recon)) / (torch.max(vi_recon) - torch.min(vi_recon))
        save_reconstructed_image(vi_recon, os.path.join(vi_recon_dir, f"{base_name}.png"))

        # çº¢å¤–å›¾åƒé‡æ„ (ir_shared + ir_diff)
        ir_recon_input = torch.cat([f_shared_ir, f_diff_ir], dim=1)
        ir_recon = decoder(ir_recon_input)
        ir_recon = (ir_recon - torch.min(ir_recon)) / (torch.max(ir_recon) - torch.min(ir_recon))
        save_reconstructed_image(ir_recon, os.path.join(ir_recon_dir, f"{base_name}.png"))

        # ---------------- æ–°å¢ç‰¹å¾ç»„åˆé‡æ„ ---------------- #
        # å¯è§å…‰å…±äº«ç‰¹å¾ + çº¢å¤–å·®å¼‚ç‰¹å¾
        vi_shared_ir_diff_input = torch.cat([f_shared_vi, f_diff_ir], dim=1)
        vi_shared_ir_diff_recon = decoder(vi_shared_ir_diff_input)
        vi_shared_ir_diff_recon = (vi_shared_ir_diff_recon - torch.min(vi_shared_ir_diff_recon)) / (
                    torch.max(vi_shared_ir_diff_recon) - torch.min(vi_shared_ir_diff_recon))
        save_reconstructed_image(vi_shared_ir_diff_recon, os.path.join(vi_shared_ir_diff_dir, f"{base_name}.png"))

        # çº¢å¤–å…±äº«ç‰¹å¾ + å¯è§å…‰å·®å¼‚ç‰¹å¾
        ir_shared_vi_diff_input = torch.cat([f_shared_ir, f_diff_vi], dim=1)
        ir_shared_vi_diff_recon = decoder(ir_shared_vi_diff_input)
        ir_shared_vi_diff_recon = (ir_shared_vi_diff_recon - torch.min(ir_shared_vi_diff_recon)) / (
                    torch.max(ir_shared_vi_diff_recon) - torch.min(ir_shared_vi_diff_recon))
        save_reconstructed_image(ir_shared_vi_diff_recon, os.path.join(ir_shared_vi_diff_dir, f"{base_name}.png"))

        if batch_idx == 0 or (batch_idx + 1) % 10 == 0:
            print(f"âœ… Processed {batch_idx + 1}/{len(dataset)}: {base_name}")

    print(f"ğŸ‰ Reconstruction complete. Results saved to:")
    print(f"  - Visible reconstructed (vi_shared + vi_diff): {vi_recon_dir}")
    print(f"  - Infrared reconstructed (ir_shared + ir_diff): {ir_recon_dir}")
    print(f"  - Mixed reconstructed (vi_shared + ir_diff): {vi_shared_ir_diff_dir}")
    print(f"  - Mixed reconstructed (ir_shared + vi_diff): {ir_shared_vi_diff_dir}")


# ---------------- CLIå…¥å£ ---------------- #
if __name__ == "__main__":
    # æƒé‡è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™…è®­ç»ƒå¥½çš„æƒé‡ï¼‰
    student_ckpt = "checkpoints_teacher_student_train1_plus_noxinxipinjin/best_student.pth"
    decoder_ckpt = "checkpoints_teacher_student_train1_plus_noxinxipinjin/best_decoder.pth"

    # æ•°æ®å’Œè¾“å‡ºè·¯å¾„
    vi_dir = "train_data/MSRS/test/vi"
    ir_dir = "train_data/MSRS/test/ir"
    output_dir = "results/reconstruction_noxinxipinjin_ceshi_test"  # æ ¹ç›®å½•ï¼Œä¸‹åˆ†å­ç›®å½•ä¿å­˜å››ç§é‡æ„ç»“æœ

    run_reconstruction_test(student_ckpt, decoder_ckpt, vi_dir, ir_dir, output_dir)